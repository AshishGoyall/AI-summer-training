{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMX3zExVMxBPbkVmeoO4Pgb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JjYDFiKlO24P","executionInfo":{"status":"ok","timestamp":1721112424517,"user_tz":-330,"elapsed":14156,"user":{"displayName":"Ashish Goyal","userId":"01019334866192868246"}},"outputId":"c59fcbf6-daab-457d-a3a1-ea02929c4cee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169001437/169001437 [==============================] - 2s 0us/step\n","(50000, 32, 32, 3) (50000, 1)\n","(10000, 32, 32, 3) (10000, 1)\n"]}],"source":["from tensorflow import keras\n","import numpy as np\n","\n","\n","(Xtrain,ytrain),(Xtest,ytest) = keras.datasets.cifar100.load_data(label_mode='fine')\n","print(Xtrain.shape,ytrain.shape)\n","print(Xtest.shape,ytest.shape)"]},{"cell_type":"code","source":["# create the CNN model\n","cnn_model = keras.models.Sequential() # empty framework\n","# Convolutinal layer 1\n","cnn_model.add(keras.layers.Conv2D(10,3,activation='relu',input_shape=(32,32,3)))\n","# maxpooling -1\n","cnn_model.add(keras.layers.MaxPool2D((2,2)))\n","\n","# Convolutinal layer 2\n","cnn_model.add(keras.layers.Conv2D(50,3,activation='relu'))\n","# maxpooling -2\n","cnn_model.add(keras.layers.MaxPool2D((2,2)))\n","\n","# feed forwards network\n","cnn_model.add(keras.layers.Flatten()) # input layer\n","cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL1\n","cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL2\n","cnn_model.add(keras.layers.Dense(200,activation='relu')) # HL3\n","cnn_model.add(keras.layers.Dense(len(np.unique(ytrain)))) # Output layer\n","\n","# optimizer\n","loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","cnn_model.compile(optimizer='sgd',loss = loss,metrics=['accuracy'])\n","cnn_model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OyfKaZdQpHT","executionInfo":{"status":"ok","timestamp":1721112425718,"user_tz":-330,"elapsed":1202,"user":{"displayName":"Ashish Goyal","userId":"01019334866192868246"}},"outputId":"df633488-15fe-44b5-a889-f4fc2fae7efc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 10)        280       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 15, 15, 10)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 13, 13, 50)        4550      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 6, 6, 50)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 1800)              0         \n","                                                                 \n"," dense (Dense)               (None, 200)               360200    \n","                                                                 \n"," dense_1 (Dense)             (None, 200)               40200     \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               40200     \n","                                                                 \n"," dense_3 (Dense)             (None, 100)               20100     \n","                                                                 \n","=================================================================\n","Total params: 465530 (1.78 MB)\n","Trainable params: 465530 (1.78 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# train the cnn along with the validation data\n","history = cnn_model.fit(Xtrain,ytrain,epochs=100,validation_data=(Xtest,ytest))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6HboI7lQuJS","executionInfo":{"status":"ok","timestamp":1721113157621,"user_tz":-330,"elapsed":731905,"user":{"displayName":"Ashish Goyal","userId":"01019334866192868246"}},"outputId":"0d740a85-1705-4119-f2fc-fca79fd6f25e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1563/1563 [==============================] - 12s 5ms/step - loss: 4.6776 - accuracy: 0.0084 - val_loss: 4.6047 - val_accuracy: 0.0112\n","Epoch 2/100\n","1563/1563 [==============================] - 10s 7ms/step - loss: 4.6045 - accuracy: 0.0100 - val_loss: 4.6025 - val_accuracy: 0.0106\n","Epoch 3/100\n","1563/1563 [==============================] - 10s 6ms/step - loss: 4.6018 - accuracy: 0.0104 - val_loss: 4.5862 - val_accuracy: 0.0130\n","Epoch 4/100\n","1563/1563 [==============================] - 10s 6ms/step - loss: 4.5543 - accuracy: 0.0168 - val_loss: 4.5267 - val_accuracy: 0.0229\n","Epoch 5/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 4.4428 - accuracy: 0.0294 - val_loss: 4.3942 - val_accuracy: 0.0386\n","Epoch 6/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 4.3574 - accuracy: 0.0446 - val_loss: 4.3298 - val_accuracy: 0.0501\n","Epoch 7/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 4.2712 - accuracy: 0.0631 - val_loss: 4.2540 - val_accuracy: 0.0683\n","Epoch 8/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 4.1617 - accuracy: 0.0824 - val_loss: 4.1364 - val_accuracy: 0.0846\n","Epoch 9/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 4.0208 - accuracy: 0.1016 - val_loss: 3.9459 - val_accuracy: 0.1167\n","Epoch 10/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.8899 - accuracy: 0.1194 - val_loss: 3.9519 - val_accuracy: 0.1050\n","Epoch 11/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.7740 - accuracy: 0.1371 - val_loss: 3.8836 - val_accuracy: 0.1309\n","Epoch 12/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.6789 - accuracy: 0.1492 - val_loss: 3.9019 - val_accuracy: 0.1160\n","Epoch 13/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 3.5901 - accuracy: 0.1637 - val_loss: 3.8245 - val_accuracy: 0.1399\n","Epoch 14/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.5207 - accuracy: 0.1753 - val_loss: 3.7151 - val_accuracy: 0.1461\n","Epoch 15/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.4791 - accuracy: 0.1815 - val_loss: 3.8831 - val_accuracy: 0.1299\n","Epoch 16/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.4049 - accuracy: 0.1955 - val_loss: 3.7365 - val_accuracy: 0.1518\n","Epoch 17/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.3375 - accuracy: 0.2053 - val_loss: 3.7739 - val_accuracy: 0.1471\n","Epoch 18/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.2721 - accuracy: 0.2167 - val_loss: 3.7349 - val_accuracy: 0.1559\n","Epoch 19/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.2106 - accuracy: 0.2252 - val_loss: 3.7780 - val_accuracy: 0.1504\n","Epoch 20/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.1483 - accuracy: 0.2358 - val_loss: 3.7462 - val_accuracy: 0.1769\n","Epoch 21/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 3.0805 - accuracy: 0.2499 - val_loss: 3.7296 - val_accuracy: 0.1625\n","Epoch 22/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 3.0301 - accuracy: 0.2566 - val_loss: 3.8043 - val_accuracy: 0.1625\n","Epoch 23/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.9834 - accuracy: 0.2666 - val_loss: 3.8844 - val_accuracy: 0.1573\n","Epoch 24/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.9277 - accuracy: 0.2749 - val_loss: 3.8214 - val_accuracy: 0.1651\n","Epoch 25/100\n","1563/1563 [==============================] - 6s 4ms/step - loss: 2.8685 - accuracy: 0.2891 - val_loss: 3.8625 - val_accuracy: 0.1668\n","Epoch 26/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.8227 - accuracy: 0.2967 - val_loss: 3.9015 - val_accuracy: 0.1712\n","Epoch 27/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.7717 - accuracy: 0.3021 - val_loss: 4.0522 - val_accuracy: 0.1439\n","Epoch 28/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.7452 - accuracy: 0.3108 - val_loss: 4.0006 - val_accuracy: 0.1642\n","Epoch 29/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.6848 - accuracy: 0.3234 - val_loss: 3.9677 - val_accuracy: 0.1674\n","Epoch 30/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.6492 - accuracy: 0.3286 - val_loss: 4.0889 - val_accuracy: 0.1664\n","Epoch 31/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.6029 - accuracy: 0.3399 - val_loss: 4.2426 - val_accuracy: 0.1619\n","Epoch 32/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.5595 - accuracy: 0.3484 - val_loss: 4.1267 - val_accuracy: 0.1601\n","Epoch 33/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.5232 - accuracy: 0.3547 - val_loss: 4.2811 - val_accuracy: 0.1607\n","Epoch 34/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.4825 - accuracy: 0.3638 - val_loss: 4.3583 - val_accuracy: 0.1625\n","Epoch 35/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.4606 - accuracy: 0.3678 - val_loss: 4.3402 - val_accuracy: 0.1625\n","Epoch 36/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.4286 - accuracy: 0.3743 - val_loss: 4.5678 - val_accuracy: 0.1458\n","Epoch 37/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.3703 - accuracy: 0.3863 - val_loss: 4.3324 - val_accuracy: 0.1653\n","Epoch 38/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.3554 - accuracy: 0.3902 - val_loss: 4.7255 - val_accuracy: 0.1516\n","Epoch 39/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.3348 - accuracy: 0.3917 - val_loss: 4.5350 - val_accuracy: 0.1549\n","Epoch 40/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.2883 - accuracy: 0.4055 - val_loss: 4.6156 - val_accuracy: 0.1564\n","Epoch 41/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.2664 - accuracy: 0.4075 - val_loss: 4.8624 - val_accuracy: 0.1501\n","Epoch 42/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.2365 - accuracy: 0.4159 - val_loss: 4.9862 - val_accuracy: 0.1497\n","Epoch 43/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.2042 - accuracy: 0.4205 - val_loss: 5.0029 - val_accuracy: 0.1464\n","Epoch 44/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.1858 - accuracy: 0.4249 - val_loss: 4.8459 - val_accuracy: 0.1457\n","Epoch 45/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 2.1711 - accuracy: 0.4288 - val_loss: 4.8657 - val_accuracy: 0.1407\n","Epoch 46/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.1501 - accuracy: 0.4350 - val_loss: 4.8228 - val_accuracy: 0.1547\n","Epoch 47/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.1277 - accuracy: 0.4391 - val_loss: 5.0204 - val_accuracy: 0.1605\n","Epoch 48/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.0811 - accuracy: 0.4478 - val_loss: 5.0216 - val_accuracy: 0.1581\n","Epoch 49/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.0813 - accuracy: 0.4484 - val_loss: 5.0514 - val_accuracy: 0.1489\n","Epoch 50/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.0510 - accuracy: 0.4557 - val_loss: 5.1843 - val_accuracy: 0.1444\n","Epoch 51/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 2.0367 - accuracy: 0.4608 - val_loss: 5.1161 - val_accuracy: 0.1518\n","Epoch 52/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.0240 - accuracy: 0.4629 - val_loss: 5.3369 - val_accuracy: 0.1485\n","Epoch 53/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 2.0025 - accuracy: 0.4672 - val_loss: 5.1259 - val_accuracy: 0.1550\n","Epoch 54/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.9895 - accuracy: 0.4699 - val_loss: 5.3115 - val_accuracy: 0.1454\n","Epoch 55/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.9798 - accuracy: 0.4747 - val_loss: 5.6341 - val_accuracy: 0.1339\n","Epoch 56/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.9540 - accuracy: 0.4795 - val_loss: 5.3250 - val_accuracy: 0.1524\n","Epoch 57/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.9276 - accuracy: 0.4844 - val_loss: 5.3996 - val_accuracy: 0.1441\n","Epoch 58/100\n","1563/1563 [==============================] - 6s 4ms/step - loss: 1.9405 - accuracy: 0.4839 - val_loss: 5.5968 - val_accuracy: 0.1460\n","Epoch 59/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.9389 - accuracy: 0.4859 - val_loss: 5.3663 - val_accuracy: 0.1472\n","Epoch 60/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.9287 - accuracy: 0.4875 - val_loss: 5.6611 - val_accuracy: 0.1510\n","Epoch 61/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.9159 - accuracy: 0.4893 - val_loss: 5.4258 - val_accuracy: 0.1518\n","Epoch 62/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.8809 - accuracy: 0.4966 - val_loss: 5.3801 - val_accuracy: 0.1472\n","Epoch 63/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.8597 - accuracy: 0.5050 - val_loss: 5.6306 - val_accuracy: 0.1482\n","Epoch 64/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.8570 - accuracy: 0.5043 - val_loss: 5.5878 - val_accuracy: 0.1455\n","Epoch 65/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.8608 - accuracy: 0.5046 - val_loss: 5.6826 - val_accuracy: 0.1437\n","Epoch 66/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.8257 - accuracy: 0.5127 - val_loss: 5.8936 - val_accuracy: 0.1432\n","Epoch 67/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.8573 - accuracy: 0.5067 - val_loss: 5.9373 - val_accuracy: 0.1450\n","Epoch 68/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.8497 - accuracy: 0.5083 - val_loss: 5.7672 - val_accuracy: 0.1455\n","Epoch 69/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.8271 - accuracy: 0.5113 - val_loss: 5.7935 - val_accuracy: 0.1516\n","Epoch 70/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.8338 - accuracy: 0.5115 - val_loss: 5.8692 - val_accuracy: 0.1507\n","Epoch 71/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.7848 - accuracy: 0.5252 - val_loss: 5.8087 - val_accuracy: 0.1405\n","Epoch 72/100\n","1563/1563 [==============================] - 6s 4ms/step - loss: 1.7942 - accuracy: 0.5195 - val_loss: 6.0181 - val_accuracy: 0.1398\n","Epoch 73/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7634 - accuracy: 0.5299 - val_loss: 5.8591 - val_accuracy: 0.1531\n","Epoch 74/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.8013 - accuracy: 0.5218 - val_loss: 6.0504 - val_accuracy: 0.1465\n","Epoch 75/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7870 - accuracy: 0.5240 - val_loss: 5.9263 - val_accuracy: 0.1479\n","Epoch 76/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.7729 - accuracy: 0.5275 - val_loss: 6.1803 - val_accuracy: 0.1409\n","Epoch 77/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.7672 - accuracy: 0.5296 - val_loss: 6.3676 - val_accuracy: 0.1405\n","Epoch 78/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7692 - accuracy: 0.5294 - val_loss: 6.0327 - val_accuracy: 0.1447\n","Epoch 79/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7352 - accuracy: 0.5367 - val_loss: 6.1458 - val_accuracy: 0.1489\n","Epoch 80/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7475 - accuracy: 0.5376 - val_loss: 6.1896 - val_accuracy: 0.1509\n","Epoch 81/100\n","1563/1563 [==============================] - 6s 4ms/step - loss: 1.7273 - accuracy: 0.5402 - val_loss: 6.3836 - val_accuracy: 0.1309\n","Epoch 82/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.7274 - accuracy: 0.5385 - val_loss: 6.2873 - val_accuracy: 0.1396\n","Epoch 83/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7089 - accuracy: 0.5449 - val_loss: 6.0917 - val_accuracy: 0.1469\n","Epoch 84/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7147 - accuracy: 0.5465 - val_loss: 6.9737 - val_accuracy: 0.1269\n","Epoch 85/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.7117 - accuracy: 0.5469 - val_loss: 6.4332 - val_accuracy: 0.1367\n","Epoch 86/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.7149 - accuracy: 0.5470 - val_loss: 6.3817 - val_accuracy: 0.1422\n","Epoch 87/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7270 - accuracy: 0.5433 - val_loss: 6.3226 - val_accuracy: 0.1456\n","Epoch 88/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.6712 - accuracy: 0.5552 - val_loss: 6.3899 - val_accuracy: 0.1326\n","Epoch 89/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.6840 - accuracy: 0.5532 - val_loss: 6.6539 - val_accuracy: 0.1370\n","Epoch 90/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.6886 - accuracy: 0.5543 - val_loss: 6.7806 - val_accuracy: 0.1071\n","Epoch 91/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.6870 - accuracy: 0.5513 - val_loss: 6.9020 - val_accuracy: 0.1356\n","Epoch 92/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.7246 - accuracy: 0.5471 - val_loss: 6.4858 - val_accuracy: 0.1309\n","Epoch 93/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.7000 - accuracy: 0.5517 - val_loss: 6.5555 - val_accuracy: 0.1423\n","Epoch 94/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.6881 - accuracy: 0.5530 - val_loss: 6.7234 - val_accuracy: 0.1268\n","Epoch 95/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.6840 - accuracy: 0.5557 - val_loss: 6.4297 - val_accuracy: 0.1472\n","Epoch 96/100\n","1563/1563 [==============================] - 8s 5ms/step - loss: 1.6742 - accuracy: 0.5575 - val_loss: 6.5820 - val_accuracy: 0.1399\n","Epoch 97/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.6528 - accuracy: 0.5654 - val_loss: 6.3075 - val_accuracy: 0.1464\n","Epoch 98/100\n","1563/1563 [==============================] - 7s 4ms/step - loss: 1.6741 - accuracy: 0.5585 - val_loss: 6.7404 - val_accuracy: 0.1404\n","Epoch 99/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.6588 - accuracy: 0.5634 - val_loss: 6.3904 - val_accuracy: 0.1371\n","Epoch 100/100\n","1563/1563 [==============================] - 7s 5ms/step - loss: 1.6574 - accuracy: 0.5610 - val_loss: 6.9411 - val_accuracy: 0.1299\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FugiDKU_gSwj"},"execution_count":null,"outputs":[]}]}